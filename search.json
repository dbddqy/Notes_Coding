[{"title":"[Theory] [Probabilistic Robotics] ch2","url":"https://dbddqy.github.io/2020/07/23/t_probabilistic-robotics-ch2/","content":"<h1 id=\"Recursive-State-Estimation\"><a href=\"#Recursive-State-Estimation\" class=\"headerlink\" title=\"Recursive State Estimation\"></a>Recursive State Estimation</h1><h2 id=\"Conditional-Independence\"><a href=\"#Conditional-Independence\" class=\"headerlink\" title=\"Conditional Independence\"></a>Conditional Independence</h2><p><em>x</em> and <em>y</em> are independent under the condition <em>z</em>:<br>$$<br>p(x,y|z) = p(x|z)p(y|z) \\tag{2.17}<br>$$</p>\n<p>which is equivalent to:<br>$$<br>\\begin{cases}<br>     p(x|z) = p(x|z,y)<br>\\\\ p(y|z) = p(y|z,x) \\tag{2.18-19}<br>\\end{cases}<br>$$<br><strong>Proof</strong>:</p>\n<p>WLOG, insert (2.18) into (2.17) right side, get<br>$$<br>p(x|z,y)p(y|z) = \\frac{p(x|z,y)p(y,z)}{p(z)} = \\frac{p(x,y,z)}{p(z)} = p(x,y|z)<br>$$<br>however x and y are not necessarily independent, see book (2.20-21)</p>\n<h2 id=\"Probabilistic-Generative-Laws\"><a href=\"#Probabilistic-Generative-Laws\" class=\"headerlink\" title=\"Probabilistic Generative Laws\"></a>Probabilistic Generative Laws</h2><p><strong>Robot States</strong>: x<sub>0</sub>, x<sub>1</sub>, … , x<sub>t</sub></p>\n<p><strong>Environment Measurement</strong>: z<sub>1</sub>, … , z<sub>t</sub></p>\n<p><strong>Control data</strong>: u<sub>1</sub>, … , u<sub>t</sub></p>\n<p>(assume take action u first, than take measurement z)</p>\n<p>If x is <strong>complete</strong>, then x<sub>t</sub> only depends on x<sub>t-1</sub> and u<sub>t</sub>:<br>$$<br>p(x_t|x_{0:t-1},z_{1:t-1},u_{1:t}) = p(x_t|x_{t-1}, u_t) \\tag{2.31}<br>$$<br>and z<sub>t</sub> depends only on x<sub>t</sub>:<br>$$<br>p(z_t|x_{0:t},z_{1:t-1},u_{1:t}) = p(z_t|x_t) \\tag{2.32}<br>$$<br>(2.31) is called <strong>state transition probability</strong> and (2.32) is called <strong>measurement probability</strong>. They together form the <strong>Hidden Markov Model</strong>.</p>\n<p><img src=\"/pics/HMM.png\" alt=\"\"></p>\n<h2 id=\"Belief-Distributions\"><a href=\"#Belief-Distributions\" class=\"headerlink\" title=\"Belief Distributions\"></a>Belief Distributions</h2><p><strong>Belief</strong>: with all the measurements and control data, the distribution of state <em>x</em>, where the robot believes it is.</p>\n<p>Before measurement:<br>$$<br>\\overline{bel}(x_t) = p(x_t | z_{1:t-1}, u_{1:t}) \\tag{2.34}<br>$$<br>After measurement:<br>$$<br>bel(x_t) = p(x_t | z_{1:t}, u_{1:t}) \\tag{2.33}<br>$$</p>\n<h2 id=\"Bayes-Filters\"><a href=\"#Bayes-Filters\" class=\"headerlink\" title=\"Bayes Filters\"></a>Bayes Filters</h2><p><strong>Prediction</strong>:<br>$$<br>\\overline{bel}(x_i) = \\int{p(x_t | u_t, x_{t-1})bel(x_{t-1})}dx_{t-1}<br>$$<br><strong>Correction</strong> (measurement update):<br>$$<br>bel(x_i) = \\eta{p(z_t | x_t)\\overline{bel}(x_t)}<br>$$</p>\n","categories":["theory"],"tags":["probabilistic robotics","robotics"]},{"title":"about","url":"https://dbddqy.github.io/about/index.html","content":"","categories":[],"tags":[]},{"title":"category","url":"https://dbddqy.github.io/category/index.html","content":"","categories":[],"tags":[]},{"title":"link","url":"https://dbddqy.github.io/link/index.html","content":"","categories":[],"tags":[]},{"title":"search","url":"https://dbddqy.github.io/search/index.html","content":"","categories":[],"tags":[]},{"title":"project","url":"https://dbddqy.github.io/project/index.html","content":"","categories":[],"tags":[]},{"title":"tag","url":"https://dbddqy.github.io/tag/index.html","content":"","categories":[],"tags":[]}]